\chapter{\colorbox{cyan}{Análise da eficiência de algoritmos}}
\label{analise-eficiencia-de-algoritmos}

Esse capítulo apresenta um roteiro para análise da eficiência de
algoritmos e apresenta exemplos simples de problemas e de soluções
usando esse roteiro.

Além da eficiência, algoritmos podem ser analisados quanto a
facilidade de mostrar ou provar correção, simplicidade e
generalidade. 

Ao contrário da análise da eficiência, simplicidade e facilidade de
mostrar correção são critérios bastante subjetivos. É bastante difícil
estabelecer métricas para tais critérios. Generalidade, por sua vez,
pode ser medida pelo tamanho do domínio da entrada do problema
resolvido, mas há situações em que o desenvolvimento de um algoritmo
mais geral é desnecessário (pouco vantajoso) ou difícil, e tal
dificuldade ou necessidade é difícil de ser medida precisamente.

O projeto de algoritmos envolve revisão e busca de melhorias, com o
qual programadores devem se envolver. 

Em geral, o projeto de algortimos envolve a adoção de soluções que
favorecem um aspecto em detrimento de outro, e um aspecto que costuma
ser bastante influente é o tempo disponível para desenvolvimento do
programa. O desenvolvimento de algoritmos {\em ótimos\/} é uma questão
relativa ao {\em problema\/} que está sendo resolvido e, mesmo
restringindo ao aspecto de eficiência, para muitos problemas saber
dizer qual é o algoritmo ótimo é difícil e muitas vezes não tem uma
resposta conhecida. Vamos falar mais sobre esse assunto na seção
{P-vs-NP}.

% Anany Levitin cita \ref{Anany-Levitin-analysis-and-design-of-algs} a
% seguinte observação de Saint-Exupéry (que ele tirou de citação feita
% por Jon Bentley): ``Um projetista sabe que chegou à perfeição não
% quando não há mais nada a incluir, mas quando não há mais nada a
% remover''.

A prova de correção de programas é uma área da ciência da computação
que está em franca evolução, atualmente. O desenvolvimento de teorias
de tipos \cite{Sorensen98lectureson}, baseadas nos chamados ``tipos
dependentes'' \cite{Bove:2009:DTW,Nederpelt-Geuvers-2014}, tem
evoluído bastante. Esse desenvolvimento tem estimulado trabalhos com
os chamados ``assistentes de prova''
\cite{Geuvers2009:Proof-assistants}. Esses programas e linguagens, no
entanto, ainda requerem bastante treinamento e parecem ainda estar em
processo de evolução, antes que possam ser mais amplamente
usados. Atualmente, a correção da vasta maioria dos programas usados
na prática não é demonstrada, mas sujeita a testes. Provas de correção
e técnicas de teste de programas não fazem parte do escopo deste
livro; no entanto, vamos usar provas de indução e definição de
invariantes para mostrar informalmente a correção de programas.

Como usualmente, não é feita neste livro nenhuma {\em validação dos
  dados de entrada}, isto é, não é verificado que os dados de entrada
realmente estão dentro dos limites estabelecidos no enunciado de um
problema. Em programas usados na prática, essa verificação deve ser
incluída (o enunciado do problema não deve estabelecer tais limites
para os dados de entrada), mas em geral essa validação não envolve
nenhum aspecto mais relevante para a tarefa de programação (apenas
inclusão de testes para emissão de mensagens de erro no caso em que os
dados de entrada não satisfaçam a esses testes).

As seções a seguir apresentam alguns exemplos de problemas para os
quais há vamos analisar a eficiência de um algoritmo simples que os
resolve. O roteiro para análise da eficiência é o seguinte:

\begin{enumerate}

\item Determinar variável ($n$) que representa o tamanho dos dados de
  entrada.

\item Identificar operações que vão determinar a variação na
  eficiência do programa durante a execução.

\item Expresse o número de vezes que a operação é executada em função
  de $n$, chamada de expressão-determinante-da-eficiência.

\item Resolva ou simplifique a expressão-determinante-da-eficiência.

\end{enumerate}

No caso de um programa recursivo, a
expressão-determinante-da-eficiência é em geral uma expressão escrita
em função de $T(n-1)$ ou outro argumento da função $T$ (de tempo de
execução) menor que $n$, que expressa $T(n)$ de modo recursivo,
criando o que é chamado de uma {\em relação de recorrência} (uma
relação de recorrência é uma definição recursiva para a qual em geral
existe uma solução não recursiva que a simplifique, que especifica a
mesma relação). 

No caso de um programa não recursivo, a
expressão-determinante-da-eficiência é em geral um somatório, que em
geral também pode ser simplificado.

As seções seguintes apresentam exemplo de problemas simples e suas
soluções, para os quais a eficiência é analisada usando o roteiro
acima.

\section{Número de Dígitos}
\label{numero-de-digitos}

O problema é determinar o número de dígitos de um número em uma dada
base usada para representação desse número. O número e a base são
dados de entrada.

\subsection{Versão funcional}

\newcommand{\numDigs}{{\it numDigs\/}}

A versão funcional é apresentada em Haskell a seguir:

\progb{
\numDigs\ $x$ $b$\\
  \hspace*{.2cm} | $x$ < $b$   = 1\\
  \hspace*{.2cm} | \otherwise\ = 1 + \numDigs\ ($x$ `\ddiv` $b$)
}

A variável que representa o tamanho dos dados de entrada é igual a
$n$.  A variação do tempo de execução $T(n)$ é dada por (considerando
como $k$ uma constante igual ao tempo gasto pela operação de somar 1 a
um valor qualquer mais o tempo gasto pela operação de comparar o
argumento $x$ com $b$):

 \[ \begin{array}{lll}
       T(n) & = 0                  & \text{ se } n < b\\
       T(n) & = T(n `\ddiv` b) + k & \text{ caso contrário}
    \end{array}
 \]
Vamos considerar que $n$ é uma potência de $b$ --- isto é, $n = b^i$,
para algum $i\geq 0$. Essa consideração é baseada na regra .... \ldots

Para $i\geq b$, obtemos:  
 \[ \begin{array}{ll}
       T(b^i) & = T(b^{i-1}) + k \\
              & = T(b^{i-2}) + (2 \times k) \\
              & \ldots
    \end{array}
 \]
Para $n=b^i$, obtemos $T(b^i) = T(b^0) + (i\times k) = i\times k$.
Portanto, $T(n) = log_b (i\times k)$ e portanto $T(n) \asymp lg n$.

\subsection{Versão imperativa}

\newcommand{\numD}{{\it numD\/}}

A versão imperativa é similar, usando um comando de repetição em vez
de recursão:

\progb{
\numDigs\ ($n$,$b$) \\
  \hspace*{.2cm} \numD\ = 0\\
  \hspace*{.2cm}   \while\ ($n$ > $b$) \\
       \hspace*{1cm} \numD\ = \numD\ + 1\\
       \hspace*{1cm} $n$ = $n$ / $b$
}
A expressão-determinante-da-eficiência é igual a $m \times \Theta(1)$,
onde $m$ é o número de vezes que o comando de repetição é executado e
$\Theta(1)$ expressa o tempo gasto nos comandos internos ao comando de
repetição. Como a variável $n$ recebe, a cada repetição, o valor do
quociente da divisão do valor de $n$ (anterior à atribuição) por $b$,
obtemos: $T(n) \asymp m \asymp log_b n \asymp lg n$. 

Note que $T(n) \asymp lg n$ para qualquer base $b$.

Note também que $T(n)$ (e o número de repetições no \while) aumenta
logaritmicamente com um aumento (linear) no {\em valor\/} de $n$, mas
aumenta linearmente com um aumento no número de dígitos de $n$ (o
valor de $n$ aumenta exponencialmente com um aumento no número de
dígitos de $n$).

\section{Maior Elemento}
\label{maior-elemento}

\newcommand{\maxElem}{{\it maxElem\/}}

Considere o problema de encontrar o maior elemento de uma lista. 

A versão funcional apresentada abaixo simplesmente usa \foldl': 

\progb{\maxElem\ :: \Ord\ $a$ => [$a$] -> $a$\\
\maxElem\ ($a$:$x$) = \foldl' \max\ $a$ $x$ }

A função \max, definida no prelúdio de Haskell, retorna o maior entre
dois valores, passados como parâmetros:

\progb{\max\ :: \Ord\ $a$ => $a$ -> $a$ -> $a$\\
       \max\ $a$ $b$ \\
         \hspace*{.2cm} | $a$ <= $b$  = $b$
         \hspace*{.2cm} | \otherwise\ = $a$
      }
 
A função \foldl, aplicada a uma função binária $f$, um valor inicial
$z$ e uma lista, reduz a lista usando a função $f$ da esquerda para a
direita:

  \[ \text{\tt{ \foldl\ $f$ $z$ [$e_1$, $e_2$, \ldots, $e_n$] == (\ldots (($z$ `$f$` $e_1$) `$f$` $e_2$) `$f$`\ldots) `$f$` $e_n$}} \]

A função \foldl'\ se comporta de modo similar a \foldl, mas é ``menos
preguiçosa'': \foldl' $f$ força a avaliação de $f$, de modo que, {\tt
  $z$ `$f$` $e_1$} seja avaliado antes de compor a expressão ($z$
`$f$` $e_1$) `$f$` $e_2$), e assim sucessivamente.  O uso de
\foldl'\ é adequado quando a função $f$ é estrita (ou seja, quando $f$
não é preguiçosa).

\HRule
{\em Nota\/}: 

Uma função $f$ é dita estrita se (escrevendo sucintamente) $f\: \bot =
\bot$, ou seja: quando o resultado de aplicar $f$ a um argumento que
fica em ciclo infinito faz com que a chamada a $f$ fique em ciclo
infinito. O valor $\bot$ é usado para indicar ``ciclo infinito'', e
também ocorrência de erro devido a recursos, em quantidade finita,
serem consumidos para avaliação, durante a execução. 

Em Haskell, ao contrário da grande maioria das linguagens de
programação, a estratégia de avaliação de expressões é ``preguiçosa''
(em inglês, ``lazy''). Isso significa que o argumento para uma função
não é avaliado quando a expressão é chamada, mas simplesmente
substituído pelo parâmetro no corpo da função, para posterior
avaliação, se necessário. Além disso, se for necessária, na estratégia
de avaliação preguiçosa a avaliação do argumento só é feita uma única
vez. Nas outras vezes em que o argumento for usado, é usado o valor
resultante da avaliação feita na primeira vez. 

Na maioria das linguagens de programação, a estratégia de avaliação de
expressões é ``gulosa'' (em inglês, ``eager''). Nessa estratégia, o
argumento é avaliado antes de uma chamada à função. Essa estratégia
faz com que todas as funções sejam estritas.

As diferenças resultantes do uso de estratégias de avaliação
preguiçosa e gulosa estão fora do escopo deste livro. 

No entanto, vale observar que o uso de \foldl' neste exemplo não
altera a complexidade assintótica do tempo de execução, mas pode
afetar bastante a eficiência o espaço necessário, e portanto da
constante de proporcionalidade, da função que expressa o tempo de
execução.

\HRule

A relação de recorrência é $T(n) = ..... $. A
expressão-determinante-da-eficiência é ... 

  Identificar operações que vão determinar a variação na
  eficiência do programa durante a execução.

  Expresse o número de vezes que a operação é executada em função
  de $n$, chamada de expressão-determinante-da-eficiência.

  Resolva ou simplifique a expressão-determinante-da-eficiência.

A complexidade é, assim, a mesma da pesquisa sequencial em uma lista:
$O(n)$ no pior caso (onde $n$ é o tamanho da lista de elementos), pois
envolve possivelmente comparação com cada elemento.

\section{Unicidade de Elementos}

\section{Multiplicação de Matrizes}

\section{Números de Fibonacci}
